import json
import uvicorn

from typing import List, Dict, Any, AsyncGenerator
from datetime import datetime
from pydantic import BaseModel, Field

from fastapi import HTTPException, FastAPI
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from langchain.chat_models import init_chat_model
from langchain.messages import SystemMessage, HumanMessage, AIMessage
from langchain_core.messages import BaseMessage


from app.core.agent import model_usage
from app.rag.document_loader import DocumentLoader
from app.rag.vector_store import get_vector_store_manager
from app.rag.rag_retriever import get_rag_retriever

def get_model():
    return model_usage


# ==================== RAG ç³»ç»Ÿåˆå§‹åŒ– ====================
def initialize_rag_system():
    """åˆå§‹åŒ– RAG ç³»ç»Ÿï¼šåŠ è½½æ–‡æ¡£å¹¶æ„å»ºå‘é‡å­˜å‚¨"""
    print("\n" + "="*60)
    print("ğŸš€ åˆå§‹åŒ– RAG çŸ¥è¯†åº“...")
    print("="*60 + "\n")
    
    try:
        # 1. åŠ è½½æ–‡æ¡£
        loader = DocumentLoader()
        documents = loader.load_all_documents()
        
        if not documents:
            print("âš ï¸  æœªæ‰¾åˆ°ä»»ä½•æ–‡æ¡£ï¼ŒRAG åŠŸèƒ½å°†ä¸å¯ç”¨")
            return False
        
        # 2. åˆå§‹åŒ–å‘é‡å­˜å‚¨
        vector_store_manager = get_vector_store_manager()
        vector_store_manager.initialize(documents)
        
        print("="*60)
        print("âœ… RAG çŸ¥è¯†åº“åˆå§‹åŒ–å®Œæˆï¼")
        print("="*60 + "\n")
        
        return True
        
    except Exception as e:
        error_msg = str(e)
        print(f"âŒ RAG ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {error_msg}")
        
        # å¦‚æœæ˜¯ç½‘ç»œè¿æ¥é—®é¢˜ï¼Œç»™å‡ºå‹å¥½æç¤º
        if "Connection" in error_msg or "ConnectionResetError" in error_msg or "Connection aborted" in error_msg:
            print("\nğŸ’¡ æç¤ºï¼š")
            print("   è¿™å¯èƒ½æ˜¯ç½‘ç»œè¿æ¥é—®é¢˜å¯¼è‡´çš„ã€‚")
            print("   è§£å†³æ–¹æ¡ˆï¼š")
            print("   1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
            print("   2. ç¨åé‡è¯•ï¼ˆç³»ç»Ÿä¼šè‡ªåŠ¨é‡è¯•ï¼‰")
            print("   3. æˆ–è€…ä½¿ç”¨æœ¬åœ° embedding æ¨¡å‹")
            print("\n   ç³»ç»Ÿå°†ç»§ç»­è¿è¡Œï¼Œä½† RAG åŠŸèƒ½å°†ä¸å¯ç”¨ã€‚")
        else:
            import traceback
            traceback.print_exc()
        
        return False


# åœ¨æ¨¡å—åŠ è½½æ—¶åˆå§‹åŒ– RAG ç³»ç»Ÿ
_rag_initialized = initialize_rag_system()


class ContentBlock(BaseModel):
    type: str = Field(description="å†…å®¹ç±»å‹: text, image, audio")
    content: str = Field(description="å†…å®¹æ•°æ®")


class MessageRequest(BaseModel):
    content_blocks: List[ContentBlock] = Field(default=[], description="å†…å®¹å—")
    history: List[Dict[str, Any]] = Field(default=[], description="å¯¹è¯å†å²")


class MessageResponse(BaseModel):
    content: str
    timestamp: str
    role: str


def create_multimodal_message(request: MessageRequest) -> HumanMessage:
    """åˆ›å»ºå¤šæ¨¡æ€æ¶ˆæ¯"""
    message_content = []

    # å¤„ç†å†…å®¹å—
    for i, block in enumerate(request.content_blocks):
        if block.type == "text":
            message_content.append({
                "type": "text",
                "text": block.content
            })

    return HumanMessage(content=message_content[0]["text"])

def convert_history_to_messages(history: List[Dict[str, Any]], rag_context: str = "") -> List[BaseMessage]:
    """
    å°†å†å²è®°å½•è½¬æ¢ä¸º LangChain æ¶ˆæ¯æ ¼å¼ï¼Œæ”¯æŒå¤šæ¨¡æ€å†…å®¹
    
    Args:
        history: å¯¹è¯å†å²
        rag_context: RAG æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰
    """
    messages = []

    # æ„å»ºç³»ç»Ÿæ¶ˆæ¯ï¼ˆåŒ…å« RAG ä¸Šä¸‹æ–‡ï¼‰
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¤šæ¨¡æ€ RAG åŠ©æ‰‹ï¼Œå…·å¤‡ä¸ç”¨æˆ·å¯¹è¯çš„èƒ½åŠ›ï¼Œè¯·ä»¥ä¸“ä¸šã€å‡†ç¡®ã€å‹å¥½çš„æ–¹å¼å›ç­”ç”¨æˆ·æ‰€æé—®é¢˜ã€‚"""
    
    if rag_context:
        system_prompt += f"""

ä»¥ä¸‹æ˜¯æ¥è‡ªçŸ¥è¯†åº“çš„ç›¸å…³ä¿¡æ¯ï¼Œè¯·åŸºäºè¿™äº›ä¿¡æ¯å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å¦‚æœçŸ¥è¯†åº“ä¸­çš„ä¿¡æ¯ä¸è¶³ä»¥å›ç­”é—®é¢˜ï¼Œè¯·åŸºäºä½ çš„çŸ¥è¯†è¿›è¡Œå›ç­”ï¼Œä½†è¦æ˜ç¡®è¯´æ˜ä¿¡æ¯æ¥æºã€‚

ã€çŸ¥è¯†åº“ä¿¡æ¯ã€‘
{rag_context}
    """

    messages.append(SystemMessage(content=system_prompt))

    # è½¬æ¢å†å²æ¶ˆæ¯
    for i, msg in enumerate(history):
        content = msg.get("content", "")
        content_blocks = msg.get("content_blocks", [])
        message_content = []
        if msg["role"] == "user":
            for block in content_blocks:
                if block.get("type") == "text":
                    message_content.append({
                        "type": "text",
                        "text": block.get("content", "")
                    })
            messages.append(HumanMessage(content=message_content))
        elif msg["role"] == "assistant":
            messages.append(AIMessage(content=content))

    return messages







async def generate_streaming_response(
        messages: List[BaseMessage],
        user_query: str = ""
) -> AsyncGenerator[str, None]:
    """
    ç”Ÿæˆæµå¼å“åº”ï¼ˆé›†æˆ RAGï¼‰
    
    Args:
        messages: æ¶ˆæ¯åˆ—è¡¨
        user_query: ç”¨æˆ·æŸ¥è¯¢ï¼ˆç”¨äº RAG æ£€ç´¢ï¼‰
    """
    try:
        model = get_model()
        # åˆ›å»ºæµå¼å“åº”
        full_response = ""

        chunk_count = 0
        async for chunk in model.astream(messages):
            chunk_count += 1
            if hasattr(chunk, 'content') and chunk.content:
                content = chunk.content
                full_response += content

                # ç›´æ¥å‘é€æ¯ä¸ªchunkçš„å†…å®¹ï¼Œé¿å…é‡å¤
                data = {
                    "type": "content_delta",
                    "content": content,
                    "timestamp": datetime.now().isoformat()
                }
                yield f"data: {json.dumps(data, ensure_ascii=False)}\n\n"

        # å‘é€å®Œæˆä¿¡å·
        final_data = {
            "type": "message_complete",
            "full_content": full_response,
            "timestamp": datetime.now().isoformat(),
        }
        yield f"data: {json.dumps(final_data, ensure_ascii=False)}\n\n"
    except Exception as e:
        error_data = {
            "type": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }
        yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"






# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(
    title="å¤šæ¨¡æ€ RAG å·¥ä½œå° API",
    description="åŸºäº LangChain 1.0 çš„æ™ºèƒ½å¯¹è¯ API",
    version="1.0.0"
)

# é…ç½®è·¨åŸŸè®¿é—®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.post("/api/chat/stream")
async def chat_stream(request: MessageRequest):
    """æµå¼èŠå¤©æ¥å£ï¼ˆæ”¯æŒå¤šæ¨¡æ€ + RAGï¼‰"""
    try:
        # è·å–ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬
        user_query = ""
        if request.content_blocks:
            for block in request.content_blocks:
                if block.type == "text":
                    user_query = block.content
                    break
        
        # RAG æ£€ç´¢ï¼ˆå¦‚æœå·²åˆå§‹åŒ–ï¼‰
        rag_context = ""
        if _rag_initialized and user_query:
            try:
                retriever = get_rag_retriever(k=4)
                relevant_docs = await retriever.aretrieve(user_query)
                if relevant_docs:
                    rag_context = retriever.format_context(relevant_docs)
            except Exception as e:
                print(f"âš ï¸  RAG æ£€ç´¢å¤±è´¥: {e}")
        
        # è½¬æ¢æ¶ˆæ¯å†å²ï¼ˆåŒ…å« RAG ä¸Šä¸‹æ–‡ï¼‰
        messages = convert_history_to_messages(request.history, rag_context=rag_context)

        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯ï¼ˆæ”¯æŒå¤šæ¨¡æ€ï¼‰
        current_message = create_multimodal_message(request)
        messages.append(current_message)

        # è¿”å›æµå¼å“åº”
        return StreamingResponse(
            generate_streaming_response(messages, user_query=user_query),
            media_type="text/plain",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Content-Type": "text/event-stream",
            }
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))






@app.post("/api/chat")
async def chat_sync(request: MessageRequest):
    """åŒæ­¥èŠå¤©æ¥å£ï¼ˆæ”¯æŒå¤šæ¨¡æ€ + RAGï¼‰"""
    try:
        # è·å–ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬
        user_query = ""
        if request.content_blocks:
            for block in request.content_blocks:
                if block.type == "text":
                    user_query = block.content
                    break
        
        # RAG æ£€ç´¢ï¼ˆå¦‚æœå·²åˆå§‹åŒ–ï¼‰
        rag_context = ""
        if _rag_initialized and user_query:
            try:
                retriever = get_rag_retriever(k=4)
                relevant_docs = await retriever.aretrieve(user_query)
                if relevant_docs:
                    rag_context = retriever.format_context(relevant_docs)
            except Exception as e:
                print(f"âš ï¸  RAG æ£€ç´¢å¤±è´¥: {e}")
        
        # è½¬æ¢æ¶ˆæ¯å†å²ï¼ˆåŒ…å« RAG ä¸Šä¸‹æ–‡ï¼‰
        messages = convert_history_to_messages(request.history, rag_context=rag_context)

        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯ï¼ˆæ”¯æŒå¤šæ¨¡æ€ï¼‰
        current_message = create_multimodal_message(request)
        messages.append(current_message)

        # è·å–æ¨¡å‹å“åº”
        model = get_model()
        response = await model.ainvoke(messages)

        return MessageResponse(
            content=response.content,
            role="assistant",
            timestamp=datetime.now().isoformat(),
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    uvicorn.run(
        app,
        host="localhost",
        port=8000
    )